\chapter{Modellierung der Test-Daten}
\label{chap:modellierung}

Die Erweiterungen und andere Verbesserungen fließen nicht in die bisher genutzte Bibliothek \textit{SB Testing DB} ein.
Stattdessen wird der Quellcode dieser Bibliothek als Ausgangspunkt für das neue Projekt \textit{STU} (Simple Test Utils,
\url{https://github.com/Seitenbau/stu}) verwendet. \textit{STU} steht unter der Open-Source-Lizenz XYZ\todo{Welche Lizenz?}

Die bisherigen Schnittstellen sollen so weit möglich nur ergänzt und nicht verändert werden, so dass auf
\textit{SB Testing DB} basierende Tests möglichst leicht auf \textit{STU} portiert werden können. Neue bzw. angepasste
Tests können jedoch von den neuen Möglichkeiten profitieren.

Bei den Schnittstellen zur Beschreibung des Datenbankmodells für den Generator wird jedoch auf Kompatibilität verzichtet.

\section{Architektur der generierten Klassen}
\label{sec:modellierung:architektur}

Der Code-Generator aus \textit{STU} erzeugt zwei APIs für die Modellierung von DataSets:
\begin{itemize}
	\item Das \textbf{Fluent Builder API} ist ein \textbf{Java}-basiertes API. Es nutzt das Builder-Pattern in Verbindung mit
	  einem Fluent Interface (ref builder pattern).
			
	\item Das \textbf{Table Builder API} ist das \textbf{Groovy}-basierte API, das es erlaubt, die Testdaten tabellarisch
	  zu modellieren.
			
\end{itemize}

Abbildung \ref{img:architektur} stellt die Architektur grafisch dar. 

\begin{figure}[htbp]
	\centering
	 \includegraphics[scale=0.75]{images/realisierung/architektur.png}
	\caption{Architektur}\label{img:architektur}
\end{figure}
\todo{Neues Bild für Schichten}
	
Die neue Table Builder API stellt eine Schicht über der bisherigen Fluent Builder API dar. Neue Funktionen müssen 
jedoch nicht zwangsläufig in der Table Builder API hinzugefügt werden, unter Umständen kann es vorteilhaft sein, sie
direkt in das Fluent Builder API zu integrieren. Gründe dafür sind unter anderem:
\begin{itemize}
	\item \textbf{Code-Qualität}: Es gibt verschiedene Ansätze, Klassen um neue Funktionen zu erweitern oder
	  ihr Verhalten zu ändern. Unabhängig davon, ob auf Vererbung oder Delegation gesetzt wird, werden neue
		Datentypen benötigt.
			
	  Soll die Schicht der Fluent Builder API nicht verändert werden, stellt Vererbung keine Option zur Erweiterungen
		von den Klassen dar, die von der Fluent-Builder-API-Schicht selbst instantiiert werden. Eine Lösung könnten
		Adapter-Klassen sein, die sämtliche Methoden der zu adaptierenden Klasse beinhalten, aber auch die Erweiterungen.
		Eine solche Adapter-Klasse kann aus einer Vielzahl an Methoden bestehen, die nichts anderes machen, als die Aufgabe
		weiter zu delegieren.
			
		Insgesamt stellen Adapterklassen in Kombination mit Delegation keine elegante Lösungen dar. Die unübersichtlicheren 
		und aufgeblähten Klassenhierarchie ist dabei noch das kleinere Problem. Gravierender ist, dass innerhalb der
		Table Builder API konsequenterweise nur noch die Adapter-Klasse statt der ursprünglichen Klasse als Rückgabetyp
		von Methoden in Frage kommen darf. Das würde bedeuten, dass weitere Klassen adaptiert werden müssten, nur um den
		Rückgabetyp anzupassen.
			
		Vererbung hat ähnliche Nachteile was die Klassenhierarchie betrifft und würde außerdem noch Änderungen in der
		Fluent-Builder-API-Schicht nach sich ziehen. Wenn allerdings Änderungen innerhalb dieser Schicht gemacht werden,
		dann können die Erweiterungen auch direkt in dieser Schicht, also den bisherigen Klassen gemacht werden.
		So lange nur neue Funktionen hinzukommen und das Verhalten bestehender Methoden nicht verändert wird, müssen bestehende
		Tests nicht an die neuen Schnittstellen angepasst werden.
			
	\item \textbf{Mehrwert gegenüber \textit{SB Testing DB}}: Auch wenn auf das neue Table Builder API verzichtet wird,
	  bietet das Fluent Builder API einen Mehrwert gegenüber der bisherigen SB-Testing-DB-Implementierung.
	
  \item \textbf{Einheitliches Verhalten}: Beide APIs zeigen auf diese Weise ein einheitlicheres Verhalten.

\end{itemize}



\section{Entwurf der DSL}

... Vor- und Nachteile einzelner Entwürfe ...

	\subsection{DSL-Entwürfe}

		\subsubsection{Entwurf 1}
		
		Eine DSL, die sich stark an \textit{SB Testing DB} orientiert, könnte wie folgt aussehen:
		
		\begin{lstlisting}[caption=Mögliche DSL (1), label=listing:dslentwurf1]
HAASE = professor {
	name			"Haase"
	vorname   "Oliver"
	titel     "Prof. Dr."
  fakultaet "Informatik"
}

WAESCH = professor {
	name			"Wäsch"
	vorname   "Jürgen"
	titel     "Prof. Dr.-Ing."
  fakultaet "Informatik"
}
	
VSYS = lehrveranstaltung {
	name			"Verteilte Systeme"
  sws       4
	ects      5
}
	
DPATTERNS = lehrveranstaltung {
	name 			"Design Patterns"
	sws       4
	ects      3
}

...

HAASE leitet VSYS
HAASE leitet DPATTERNS
HAASE beaufsichtigt	P_DPATTERNS
WAESCH beaufsichtigt P_VSYS
...

		\end{lstlisting}
		
		Diese DSL kommt ohne manuell vergebene ID-Nummern aus und verwendet Variablennamen für die Modellierung von Beziehungen. 
		Da für jeden Wert eine eigene Zeile verwendet wird, werden umfangreiche Daten schnell unübersichtlich. Die Beschreibung
		der Beziehungen abseits der Definition der Daten erschwert den Umgang mit den Daten und die Übersicht ebenfalls.


		\subsubsection{Entwurf 2}
		
		Ein leicht abgewandelter Entwurf zeigt, wie sich die Beziehungen näher an den eigentlichen Daten beschreiben lassen könnten.
		An dem Problem, dass die Daten relativ schnell in vertikaler Richtung wachsen, ändert das jedoch nichts.
		

		\begin{lstlisting}[caption=Mögliche DSL (2), label=listing:dslentwurf2]
HAASE = professor {
	name      "Haase"
	vorname   "Oliver"
	titel     "Prof. Dr."
  fakultaet "Informatik"
	leitet    VSYS, DPATTERNS
	beaufsichtigt	P_DPATTERNS
}

WAESCH = professor {
	name      "Wäsch"
	vorname   "Jürgen"
	titel     "Prof. Dr.-Ing."
  fakultaet "Informatik"
	beaufsichtigt	P_VSYS
}
	
VSYS = lehrveranstaltung {
	name			"Verteilte Systeme"
  sws       4
	ects      5
}
	
DPATTERNS = lehrveranstaltung {
	name 			"Design Patterns"
  sws       4
	ects      3
}

...
	\end{lstlisting}
	

		\subsubsection{Entwurf 3}
		
		Der dritte Entwurf versucht die Daten durch eine tabellarische Struktur übersichtlich zu gestalten. Sie kommt mit
		wenig syntaktischem Ballast aus. Ein Label vor einer Tabelle drückt aus, welche Daten folgen (Zeilen 1 und 6). Die
		Tabelle selbst beginnt mit einer Kopfzeile, die die Spaltenreihenfolge beschreibt (Zeilen 2 und 7). Einzelne Spalten
		werden vom Oder-Operator (|) getrennt. Die erste Spalte nimmt Zeilen-Identifikatoren auf und ist von den Daten
		mit Hilfe des Double-Pipe-Operators (||) abgrenzt.

		\lstSetTiny
		\begin{lstlisting}[caption=Mögliche DSL (3), label=listing:dslentwurf3]
professor:
REF    || name    | vorname  | titel            | fakultaet    | leitet          | beaufsichtigt
HAASE  || "Haase" | "Oliver" | "Prof. Dr."      | "Informatik" | VSYS, DPATTERNS | P_DPATTERNS   
WAESCH || "Wäsch" | "Jürgen" | "Prof. Dr.-Ing." | "Informatik" |                 | P_VSYS
	
lehrveranstaltung:
REF       || name                | sws | ects
VSYS      || "Verteilte Systeme" | 4   | 5
DPATTERNS || "Design Patterns"   | 4   | 3

...
	\end{lstlisting}
	\lstSetNotmal
	
	Der Entwurf sieht vor, dass Beziehungen innerhalb beider Entitätstypen ausgedrückt werden können. So kann
	eine Tabelle um Spalten für Beziehungen ergänzt werden, die in dieser Form nicht Teil des relationalen
	Modells (\refimg{img:example_relational}) sind. Dazu gehören die Spalten "`leitet"' und "`beaufsichtigt"'
	der Professor-Tabelle. Erstere drückt die 1:n-Beziehung zu einer Lehrveranstaltung aus, letztere die
	m:n-Beziehung zu Prüfungen.
	
	Probleme bzw. Nachteile in der Darstellung können auftreten, wenn die Länge der Werte in einer Spalte stark
	variiert. Die Spaltenbreite wird vom längsten Element bestimmt. Der Entwickler ist selbst dafür verantwortlich,
	die übersichtliche Darstellung einzuhalten. Auf Tabulatoren sollte unter  Umständen verzichtet werden, da sie von
	verschiedenen Editoren unterschiedlich dargestellt werden können. Bei vielen Spalten wächst diese Darstellung
	horizontal. Bei optionalen Spalten bzw. kaum genutzte Spalten kann die tabellarische Darstellung unübersichtlich
	werden.
	
	Einige Entwicklungsumgebungen wie Eclipse bieten spezielle Block-Bearbeitungsfunktionen an, die beim Arbeiten an
	einer Tabellen-DSL hilfreich sein kann. So können beispielsweise in einer Spalte über mehrere Zeilen hinweg 
	Leerzeichen eingefügt oder entfernt werden.
	
	Zur besseren Übersicht kann es bei größeren Tabellen sinnvoll sein, den Tabellenkopf zu wiederholen.
	
  \subsection{Entscheidung}

	Der dritte Entwurf zeigt, dass eine tabellarische Schreibweise viele Schwächen der anderen Varianten ausmerzt.
	Die Darstellung wirkt übersichtlich, da Tabellen ... \todo{Hier wäre eine Quelle super, dass Menschen vertraut
	mit Tabellen sind}
	
	+ Möglichkeit, Beziehungen über eine spezielle Syntax wie in Entwurf 1 auszudrücken

\todo{Einfache Sprachdefinition, Grammatik}
	

\section{Implementierungsvorbereitung}
\label{sec:modellierung:wahlimplementierung}

Da sich die DSL in die bisherige Werkzeug-Kette von Seitenbau integrieren lassen soll
(\refsec{sec:anforderungen:allgemeineanforderungen}), sollte die DSL in Java nutzbar sein. Zwar kann eine DSL
grundsätzlich auch in Java realisiert werden, doch die Möglichkeiten diesbezüglich sind relativ eingeschränkt 
und die DSL sieht immer noch nach Java aus. Es lassen sich allerdings auch andere Sprachen im Java-Umfeld nutzen.

Eine davon ist {Groovy. Groovy ist eine dynamisch typisierte Sprache\footnote{Im Gegensatz zu statisch 
typisierten Sprachen finden bei dynamisch typisierten Typ-Überprüfungen überwiegend zur Laufzeit statt.}, die
direkt in Java-Bytecode übersetzt wird und damit auch in einer Java Virtual Machine ausgeführt wird. Sie teilt
sich das Objekt-Modell mit Java, so dass aus Groovy heraus instantiierte Objekte auch in der Host-Anwendung 
nutzbar sind (und umgekehrt). Auch wenn Java-Code bis auf wenige Ausnahmen gültiger Groovy-Code und sich dort
gleich verhält, enthält Groovy Techniken, die den Code mehr wie eine natürliche Sprache aussehen lassen.
So kann oftmals auf die Semikolons am Ende einer Anweisung verzichtet werden, und auch auf das Einklammern
von Parametern kann bei Methoden aufrufen verzichtet werden (wenn die Methode genau einen Parameter erwartet).
Außerdem kann statt dem Punkt zwischen Objekt und Methode beim Aufruf verzichtet werden.

Listing \ref{listing:groovyexamples} zeigt einen Befehl einmal in typischer Java-Syntax und einmal mit den
Syntax-Vereinfachungen von Groovy:

	\begin{lstlisting}[caption=Vereinfachung von Ausdrücken in Groovy, label=listing:groovyexamples]
myList.append("value 1").append("value 2");
myList append "value 1"  append "value 2"  
	\end{lstlisting}

Groovy hebt sich ferner durch die Möglichkeit Operatoren zu überladen und durch Closures (Funktionsabschlüsse) von
Java ab. Ein Closure ist ein Codeblock, der wie eine Funktion aufgerufen und genutzt werden kann. In Java lassen
sich Closures mit syntaktisch umfangreicheren Methoden-Objekten nachbilden. Ein Methoden-Objekt stellt eine
Instanz einer (möglicherweise anonymen) Klasse dar, die nur eine Methode implementiert. \cite[40]{GROOVY_IM_EINSATZ} 
\todo{Quelle Kent Beck Smalltalk Best Practice Patterns} 
Die Unterstützung zur Meta-Programmierung stellt sich beim Implementieren einer DSL ebenfalls als nützlich
heraus. Dadurch ist es z.B. möglich, abgeschlossene Klassen innerhalb von Groovy um Methoden zu erweitern oder auf
den Zugriff von nicht definierten Klassenelementen zu reagieren.

Aus diesen Gründen empfiehlt Ghosh in \cite[148]{DSLS_IN_ACTION} Groovy als Host für DSLs in Verbindung
mit Java-Anwendungen. 

	\subsection{Implementierungsvarianten}
	\label{sec:modellierung:implementierung:varianten}
	
	Eine DSL kann auf unterschiedliche Arten implementiert werden. Groovy bietet dafür zwei Möglichkeiten der
	Meta-Programmierung an: Laufzeit-Meta-Programmierung und Compiler-Zeit-Meta-Programmierung, letzteres in Form von
	AST-Transformationen. Beide Ansätze bieten individuelle Vorteile, die im folgenden diskutiert werden.  
	\nomenclature{AST}{Abstract Syntax Tree}


		\subsubsection{Laufzeit-Meta-Programmierung}
	  \label{sec:modellierung:implementierung:varianten:laufzeit}
		
		Eine Möglichkeit, die DSL mit Hilfe von Laufzeit-Meta-Programmierung zu implementieren sieht eine 
		Klasse zum Parsen von Closures vor, die eine Tabelle beinhalten. Diese Klasse, \texttt{TableParser},
		enthält dafür die Methode \texttt{parseTableClosure}. Die Methode soll als Ergebnis eine Liste
		von Tabellenzeilen zurückliefern. Da an dieser Stelle noch keinerlei Interpretation der Tabellenwerte
		durchgeführt wird, stellt eine Tabellenzeile selbst ebenfalls eine Liste dar - aus den Objekten
		der Spalten.
		
		Der Ansatz ist, Operator-Überladen für das Parsen zu verwenden. Soll ein binärer Operator implementiert
		werden, ist die übliche Vorgehensweise in Groovy, die Klasse des linken Operanden um eine entsprechende
		Methode für den Operator zu erweitern. Diese Methode trägt einen vorgegebenen Namen und erwartet als
		binärer Operator  den rechten Operanden als Parameter (eine  Übersicht findet sich beispielsweise in 
		\cite[58]{GROOVY_IM_EINSATZ}).
		
		Auch wenn sich dank der Möglichkeiten der Meta-Programmierung Klassen in Groovy zur Laufzeit um Methoden
		ergänzen lassen, ist dieses Vorgehen nicht empfehlenswert um eine Tabelle zu parsen. Dieser wenig
		generische Ansatz müsste jeden in den Tabellen mögliche Datentyp berücksichtigen - kommen neue Datentypen
		hinzu, müsste der Code erweitert werden.
		\todo{Mögliche ungewollte Seiteneffekte}
		
		Groovy bietet allerdings auch eine zweite Möglichkeit für das Operator-Überladen an. Anstatt den Operator
		als Methode dem linken Operand (bzw. der Klasse) hinzuzufügen, wird er als statische Methode (in einer
		beliebigen Klasse) realisiert. Da eine statische Methode ohne Kontext ausgeführt wird, benötigt sie alle
		beteiligten Operanden als Parameter. Eine solche Methode wird als Kategoriemethode bezeichnet. 
		Über das Schlüsselwort \texttt{use}\footnote{\texttt{use} wird in der Literatur meistens als Schlüsselwort
		bezeichnet, tatsächlich handelt es sich jedoch um eine Groovy-Methode in \texttt{java.lang.Object}}
		können die Kategoriemethoden in einem Closure verwendet werden. \cite[192]{GROOVY_IM_EINSATZ} 
		
		Listing \ref{listing:opoverloading.tableparser.base} zeigt das Grundgerüst des Tabellenparsers:
		
		\begin{lstlisting}[caption=Tabellen-Parser Grundgerüst mit Operator-Überladen, label=listing:opoverloading.tableparser.base]
class TableParser {
  
  static or(Object self, Object arg) {
		...
  }

  def parseTableClosure(Closure tableData){
    use(TableParser) {
      tableData()
    }
  }

}
		\end{lstlisting}
		
		Die Methode \texttt{or} erwartet zwei Parameter vom Typ \texttt{Object}. Obwohl in Groovy alle Typen von
		\texttt{Object} abgeleitet sind, gibt es Oder-Ausdrücke, bei denen diese Methode nicht aufgerufen wird.
		Ein in der Klasse definierter Operator mit passenden Datentypen wird dieser allgemeinen Methode bevorzugt,
		z.B. bei zwei \texttt{Integer}-Werten. Doch auch solche Operationen lassen sich überschreiben, wenn für
		die Datentypen passende Kategoriemethoden definiert werden.

		Der Parser in der Form kann noch nicht mit selbst definierten Spaltennamen und Bezeichner für die einzelnen
		Entitäten umgehen. Der Compiler versucht, diese Ausdrücke aufzulösen und sucht nach entsprechenden Properties.
		Properties können normale Variablen sein oder parameterlose Get-Methoden, die beim Aufruf in Groovy ohne das
		Präfix \texttt{get} und den runden Klammern verwendet werden können. Kann Groovy eine Property nicht auflösen
		ruft es in der aktuellen Klasse (bzw. dem Ausführungskotext) die Methode \texttt{propertyMissing} auf. Durch
		Überschreiben dieser Methode kann auf nicht auflösbare Bezeichner reagiert werden. Damit Groovy die
		gewünschte Methode bei der Ausführung eines Closures aufruft, kann der Ausführungskontext von Closures
		gesetzt werden. Auf diese Weise werden Properties und Methoden von der als Ausführungskontext festgelegten
		Instanz verwendet. In diesem Prototyp wird der Kontext auf den Tabellenparser selbst gesetzt.
	  Die Änderungen sind in Listing \ref{listing:opoverloading.tableparser.extended} dargestellt.

		\begin{lstlisting}[caption=Tabellen-Parser Grundgerüst mit Operator-Überladen, label=listing:opoverloading.tableparser.extended]
class TableParser {
  
  static or(Object self, Object arg) {
		...
  }
	
  static or(Integer self, Integer arg) {
		...
  }

  static or(Boolean self, Boolean arg) {
		...
	}
	
	def propertyMissing(String property) {
		...
  }
	

  def parseTableClosure(Closure tableData){
    use(TableParser) {
      tableData.delegate = this		// Change closure's context
      tableData.resolveStrategy = Closure.DELEGATE_FIRST
      tableData()
    }
  }

}
		\end{lstlisting}
		
		Die statischen Methoden haben keinen Zugriff auf Instanz-Variablen der Klasse \textit{TableParser}. Ihre Ergebnisse
		können sie demnach auch nur in statische Elementen aufbewahren. Um die Klasse Thread-sicher zu machen, d.h. das
		gleichzeitige Parsen von Tabellen aus verschiedenen Threads heraus, wird für die Ergebnisse eine threadlokale
		Liste verwendet. \todo{thread local erklären mit quelle} \cite{JAVA_CONCURRENCY_IN_PRACTICE}

		Die Laufzeit-Meta-Programmierung kann die Syntax der Sprache nicht beliebig erweitern. Groovy kennt keinen
		Double-Pipe-Operator. Deshalb kann dieser weder überladen noch über Laufzeit-Meta-Programmierung eingeführt
		werden. Folglich ist es nicht möglich, den dritten Entwurf über reine Laufzeit-Meta-Programmierung zu
		realisieren. Allerdings kann eine Syntax erreicht werden, die dem Entwurf sehr nahe kommt
		(\reflst{listing:dslentwurf3laufzeit}). Das DataSet wird als Map definiert, mit den Tabellennamen als
		Schlüsseln und Closures als Werte. Ein Platzhalter (Unterstrich) verhindert Syntax-Fehler, wenn in
		einer Spalte kein Wert vorkommt (siehe Zeile 4, Spalte "`leitet"'). Der Platzhalter könnte auch verwendet
		werden, um einem Datensatz keinen Bezeichner für Referenzen zu zu weisen. Aus Sicht des Parsers stellt
		der Unterstrich eine Variable dar.
		
		\lstSetTiny
		\begin{lstlisting}[caption=DSL-Entwurf 3 für Laufzeit-Meta-Programmierung angepasst, label=listing:dslentwurf3laufzeit]
def dataset = [
  professor: {
	  REF    | name    | vorname  | titel            | fakultaet    | leitet           | beaufsichtigt
		WAESCH | "Wäsch" | "Jürgen" | "Prof. Dr.-Ing." | "Informatik" | _                | P_VSYS
		HAASE  | "Haase" | "Oliver" | "Prof. Dr."      | "Informatik" | VSYS & DPATTERNS | P_DPATTERNS
  },

  lehrveranstaltung: {
    REF       | name                | sws | ects
    VSYS      | "Verteilte Systeme" | 4   | 5    
    DPATTERNS | "Design Patterns"   | 4   | 3    
  },
		
  ...
]		
		\end{lstlisting}
		\lstSetNotmal
		
		

		\subsubsection{AST-Transformation}
		
		Die AST-Transformationen stellen ein mächtiges Werkzeug zur Erweiterung der Syntax der Sprache dar. Mit Hilfe
		der Transformationen ist es möglich, Änderungen am AST durchzuführen, bevor er in Java-Bytecode übersetzt wird.
		
		Dass AST-Transformationen mehr syntaktische Möglichkeiten bieten, zeigt sich auch daran, dass hier der 
		Double-Pipe-Operator verwendet werden kann. Außerdem können Labels erkannt werden und Daten einer Tabelle
		müssen nicht zwangsläufig in einem eigenen Block definiert werden.
		
		Allerdings muss zum Auswerten einer Tabelle bei AST-Transformationen ein relativ großer Aufwand betrieben werden.
		Ein AST-Transformationsklasse, erhält über das Visitor-Pattern zugriff auf die abstrakten Syntaxbäume einzelner
		Module (\cite[331ff]{DESIGN_PATTERNS}). Groovy Module beinhalten Klassen, aber auch die modulspezifischen
		Import-Anweisungen. Auf die einzelnen Klassen kann erneut über das Visitor-Pattern auf die einzelnen Methoden
		zugegriffen werden. Diese lassen sich dann Statement für Statement untersuchen.
		
		Für das Parsen interessante Statements sind von den Typ \texttt{ExpressionStatement}. Es kann abgefragt werden,
		ob ein Label Teil des Statements ist. Über ein solches Label können die Daten den einzelnen Tabellen zugeordnet
		werden. Das eigentliche \texttt{ExpressionStatement} kann danach analysiert werden. Drei Arten von Ausdrücken
		sind dabei für das Parsen relevant:
		
		\begin{itemize}
			\item \textbf{\texttt{BinaryExpression}}: Ein binärer Ausdruck besteht aus zwei Operanden und einem Operator.
			  Wenn es sich beim Operator um einen Pipe oder Double-Pipe-Operator handelt, werden die linken und rechten
				Operanden, die selbst vom Typ \texttt{ExpressionStatement} sind, rekursiv behandelt.
				
			\item \textbf{\texttt{ConstantExpression}}: Konstante Ausdrücke sind Literale, die als Spaltenwert verwendet werden.
			
			
			\item \textbf{\texttt{VariableExpression}}: Ein Bezeichner einer Variablen. Dazu gehören die 
			  Spalten-Bezeichner und die Bezeichner für die einzelnen Zeilen.
		\end{itemize}
		
    Insgesamt muss viel Aufwand betrieben werden, um den AST zu analysieren. Dabei wirft die IDE-Unterstützung noch
		einige Fragezeichen auf: Die Labels werden kaum über Auto-Vervollständigung oder Vorschläge innerhalb der IDE
		nutzbar sein.
		
		
	\subsection{Implementierungsentscheidung}
	\label{sec:implementierung:entscheidung}
	
	Der Vergleich zwischen Laufzeit-Meta-Programmierung und AST-Transformation zeigt, dass sich Groovy als Host-Sprache
	für die DSL eignet. Grundsätzlich kann das Parsen der Tabelle über beide Varianten durchgeführt werden. 
	Die Laufzeit-Meta-Programmierung erlaubt zwar weniger Anpassungen an die Sprache, ist aber für
	die gewünschte DSL ausreichend und die Umsetzung einfacher. AST-Transformationen könnten zwar Mehrwert bieten, z.B.
	könnte auch der Double-Pipe-Operator genutzt werden und Labels, allerdings überwiegen die Nachteile des weniger
	ausdrucksstarken und damit wartungsunfreundicheren Codes. Als Konsequenz wird die einfachere
	Laufzeit-Meta-Programmierung verwendet.
		

\section{Änderungen am Generator-Modell}
\label{sec:modellierung:generatormodell}

	Bei den Klassen für die Modellierung des zu Grunde liegenden Datenbankmodells wird auf Abwärtskompatibilität verzichtet.
	Während das alte API auf überladene Methoden mit vielen Parametern setzt, ist das neue API entsprechend dem Builder-Pattern
	umgesetzt \cite[11ff]{EFFECTIVEJAVA2ND}. So enthält das alte API neun Methoden zum Hinzufügen einer Spalte in einer Tabelle
	enthält, wovon eine als \textit{deprecated} eingestuft ist. Dieses Design ist unübersichtlich und nur schwer erweiterbar. 
	Jeder weitere optionale Parameter könnte die Anzahl der Methoden verdoppeln. Demgegenüber gibt es beim Builder-Pattern für
	jeden optionalen Parameter eine einzelne Set-Methode.
	
	Die neuen Builder-Klassen decken den Funktionsumfang der alten API ab. Dabei werden Flags für Spalten nicht mehr über 
	ein \texttt{EnumSet} festgelegt, sondern über Methoden für die vordefinierten Flags. In Abschnitt 
	\ref{sec:modellierung:generatormodell:flags}  wird weiter auf das Thema Flags eingegangen. Darüber hinaus bieten die
	neuen Klassen die Möglichkeit, Beschreibungen zu Tabellen und Spalten hinzu zu fügen. Diese werden bei der Code-Generierung
	für die Erstellung von JavaDoc-Kommentaren verwendet (\refsec{sec:modellierung:realisierung:javadoc}).
	
	\todo{Abhängigkeitsdiagramm der neuen Builder-Klassen?}
	
	\subsection{Spalten-Flags}
	\label{sec:modellierung:generatormodell:flags}
	
	\textit{SB Testing DB} sieht verschiedene Flags für Spalten vor, die in einem \textit{Enum} zusammengefasst sind. Alle für eine Spalte 
	gesetzten Flags müssen beim Hinzufügen einer Spalte über ein \textit{EnumSet} übergeben werden. Bei dem neuen Builder-API werden
	die Flags über spezielle Methoden gesetzt.
	
	Zu den in \textit{STU} enthaltenen Standard-Spalten-Flags gehören:
	\begin{itemize}
		\item \textbf{Identifikator-Spalte}: Als Identifikator-Spalte wird die Spalte bezeichnet, die einen für die Zeile einmaligen
		  Wert enthält, über die eine Zeile zweifelsfrei identifiziert werden kann. In dieser Eigenschaft ähnelt sie dem Primärschlüssel
			in Datenbanken. Es bietet sich an, Primärschlüssel als Identifikator-Spalte zu modellieren. Dennoch gibt es keine Kausalität
			zwischen Identifikator-Spalte und Primärschlüssel: Ein Primärschlüssel muss nicht als Identifikator-Spalte modelliert werden,
			und eine Identifikator-Spalte muss kein Primärschlüssel sein.
			
			Die Identifikator-Spalte ist die Spalte, die bei Beziehungen verwendet wird, wenn das Ziel eine Tabelle und nicht eine Spalte
			der Tabelle ist. Das Flag wird über die Methode \texttt{identifierColumn} aktiviert. Dabei werden die Flags Unveränderbar und
			Einmalig ebenfalls aktiviert.

		\item \textbf{Next-Value-Methode}: \textit{SB Testing DB} (und damit auch \textit{STU}) bietet die Möglichkeit, Werte-Generatoren 
		  zu verwenden um einen Spaltenwert manuell oder auch automatisch mit einem generierten Wert zu belegen. Aufgerufen wird der 
			Generator über eine sogenannte Next-Value-Methode auf dem RowBuilder. Ihr Name setzt sich aus dem Präfix \texttt{next} und dem
			Spaltennamen zusammen. Der Generator erzeugt für die jeweilige Spalte allerdings nur dann eine Next-Value-Methode, wenn das
			entsprechende Flag über \texttt{addNextMethod()} aus dem Builder-API gesetzt wurde. Standardmäßig muss die Next-Value-Methode
			manuell aufgerufen werden, über ein Flag kann dies auch automatisch erfolgen.
			
		\item \textbf{Automatischer Aufruf der Next-Value-Methode}: Ist dieses Flag aktiviert, wird die Next-Value-Methode beim 
		  Anlegen einer neuen Tabellenzeile automatisch aufgerufen. Beim Setzen des Flags über die Builder-Methode
			\texttt{autoInvokeNext()} wird automatisch auch das Flag zum Generieren der Next-Value-Methode gesetzt. 
			
		\item \textbf{Auto Increment}: ... DBUNIT-Flag ... implizit addNextMethod
		
		\item \textbf{Unveränderbar}: Ist dieses Flag gesetzt, kann ein Wert in einer Spalte nur ein Mal gesetzt werden, und danach
		  nicht mehr verändert werden. Wenn das Flag zum automatischen Aufruf der Next-Value-Methode aktiviert ist, kann der
			automatisch erzeugte Wert allerdings überschrieben werden. Die Methode zum
			Aktivieren des Flags heißt \texttt{immutable()}.
		
		\item \textbf{Einmalig}: Dieses Flag gibt an, dass die Werte einer Spalte nur jeweils ein Mal vorkommen, und sie deshalb
		  zur Identifikation einer Zeile verwendet werden können. Das Flag sollte auch nur dann verwendet werden, wenn eine solche
			Identifikation erwünscht ist.
			
			Aufgrund des Anwendungszwecks wird das Flag Unveränderbar implizit aktiviert. Das Einmalig-Flag wird über die Methode
			\texttt{unique()} aktiviert und setzt keine Unique-Eigenschaft in der Datenbank voraus.
		  
	\end{itemize}
	
	
	\subsection{Modellierung von Relationen über Builder-Klassen}
	
	
	\subsection{Alte und neue Builder-Klassen im Vergleich}
	\label{sec:modellierung:generatormodell:buildervergleich}
	
	Die Vorteile der Umstellung auf das Builder-Pattern sollen die beiden folgenden Listings zeigen. Sie zeigen
	die Modellierung der Datenbank für den Generator. Der Übersicht halber wurde der Code auf die Anweisungen
	im Konstruktor der Modell-Klasse und die Definition von zwei Tabellen reduziert. Listing 
	\ref{listing:model:builder:old} zeigt die Modellierung in \textit{SB Testing DB}, während Listing
	\ref{listing:model:builder:new} die in \textit{STU} eingeführten Builder veranschaulicht.
	
	\begin{lstlisting}[caption=Beispiel SB-Testing-DB-Builder, label=listing:model:builder:old]
database("Hochschule");
packageName("com.seitenbau.sbtesting.dbunit.hochschule");

Table professoren = addTable("professor")
		.addColumn("id", DataType.BIGINT, Flags.AutoInvokeNextIdMethod) 
		.addColumn("name", DataType.VARCHAR)
		.addColumn("vorname", DataType.VARCHAR)
		.addColumn("titel", DataType.VARCHAR)
		.addColumn("fakultaet", DataType.VARCHAR);

Table lehrveranstaltungen = addTable("lehrveranstaltung")
		.addColumn("id", DataType.BIGINT, Flags.AutoInvokeNextIdMethod)
		.addColumn("professor_id", DataType.BIGINT, professoren.ref("id"))
		.addColumn("name", DataType.VARCHAR)
		.addColumn("sws", DataType.INTEGER)
		.addColumn("ects", DataType.DOUBLE);
  \end{lstlisting}
	
	In diesem Beispiel - inkl. der nicht dargestellten Tabellen-Definitionen - werden lediglich drei der
	insgesamt neun \texttt{addColumn}-Methoden verwendet.
	
	Beide Varianten ähneln sich, Unterschiede liegen - mit Ausnahme der Flags und Relationen - eher im Detail.
	Die kürzeren Parameterlisten und die zusätzlichen Funktionen führen dazu, dass die selben Modelle in
	\textit{STU} einige Zeilen länger werden. Die gewonnene Ausdrucksstärke macht diesen Nachteil allerdings
	mehr als wett.
	
	\begin{lstlisting}[caption=Beispiel \textit{STU}-Builder, label=listing:model:builder:new]
database("Hochschule");
packageName("com.seitenbau.stu.dbunit.hochschule");
enableTableModelClassesGeneration();

Table professoren = table("professor")
		.description("Die Tabelle mit den Professoren der Hochschule")
		.column("id", DataType.BIGINT) 
			.identifierColumn() 
			.autoInvokeNext()
		.column("name", DataType.VARCHAR)
		.column("vorname", DataType.VARCHAR)
		.column("titel", DataType.VARCHAR)
		.column("fakultaet", DataType.VARCHAR)
	.build();

Table lehrveranstaltungen = table("lehrveranstaltung")
		.description("Die Tabelle mit den Lehrveranstaltungen der Hochschule")
		.column("id", DataType.BIGINT)
			.identifierColumn() 
			.autoInvokeNext()
		.column("professor_id", DataType.BIGINT)
			.reference
				.local
				  .name("geleitetVon")
					.description("Gibt an, von welchem Professor eine Lehrveranstaltung geleitet wird.")
				.foreign(professoren)
				  .name("leitet")
					.description("Gibt an, welche Lehrveranstaltungen ein Professor leitet.")
		.column("name", DataType.VARCHAR)
		.column("sws", DataType.INTEGER)
		.column("ects", DataType.DOUBLE)
	.build();	
	\end{lstlisting}



\section{Realisisierung}
\label{sec:modellierung:realisierung}

Im Folgenden wir die Realisierung der DSL beschrieben. Dabei werden einige Implementierungsdetails beschrieben und auch
gezeigt, wie die DSL praktisch genutzt werden kann. 
Die DSL sollte möglichst guten Support durch die IDE bieten, um die Arbeit mit den Tabellen zu vereinfachen. Dazu gehört, 
dass Bezeichner wie Tabellen- und Spaltennamen nicht nur erkannt werden, sondern auch automatisch vervollständigt werden können.
Die in Listing \ref{listing:dslentwurf3laufzeit} gezeigte Variante kann diesem Anspruch nicht genügen. Falsche Tabellennamen können
erst zur Laufzeit festgestellt werden und auch für die Spaltenbezeichner kann es so keinen IDE-Support geben, da sie von der
Tabelle abhängig. Der IDE-Support wird über die neuen DataSet-Builder-Klassen realisiert.

  \subsection{Neue DataSet-Builder-Klassen}
	\label{sec:modellierung:realisierung:neuebuilder}
	
	Für die tabellarisch definierten DataSets wird eine neue Builder-Klasse generiert, die über Komposition und Delegation die
	bisherige, auf dem Fluent-Builder-API-basierende DataSet-Klasse nutzt.

  Der Großteil des IDE-Supports wird über Adapter-Klassen für die bisherigen Tabellen realisiert. Zu jeder Tabellen-Klasse wird
	eine zusätzliche Adapter-Klasse generiert. Dort sind die Tabellen-spezifischen Spaltenbezeichner für die tabellarische DSL
	definiert. Die Methode \texttt{rows} startet das Parsen der Tabellenzeilen, die wie im Entwurf als Closure übergeben werden.
	Innerhalb dieses Closures sind die in der Tabelle definierten Bezeichner nutzbar. Neben den Spaltenbezeichnern wird auch ein
	Spaltenbezeichner \texttt{REF} und auch der Platzhalter (Unterstrich) generiert. Die Adapter nutzen intern eine aggregierte
	Tabellen-Klasse. Dabei bildet der Adapter die Schnittstelle der Tabellen-Klasse nach und delegiert die Aufrufe.
	
	Jeder Spaltenbezeichner stellt eine anonyme Klasse dar, die die abstrakte Klasse \texttt{ColumnBinding} erweitert. Diese 
	enthält unter anderem Meta-Informationen zu der zugehörigen Spalte auch Methoden, die das Parsen der Tabellen erleichert
	(siehe Abschnitt \ref{sec:modellierung:realisierung:parser}). 

	Für jede Tabelle gibt es in der Builder-Klasse eine öffentliche Instanz der Adapter-Klasse. Auf diese Weise wird der
	IDE-Support bzgl. der Tabellennamen sichergestellt. Das Klassendiagramm ist Abbildung \ref{img:builderarchitecture} dargestellt.

	\begin{figure}[htbp]
		\centering
		 \includegraphics[width=0.6\textwidth]{images/realisierung/builderarchitecture.pdf}
		\caption{Klassendiagramm der DataSet-Builder}\label{img:builderarchitecture}
	\end{figure}
	
  
	



% http://martinfowler.com/eaaCatalog/gateway.html
% http://martinfowler.com/eaaCatalog/repository.html
% http://martinfowler.com/eaaCatalog/registry.html

		
	\subsection{Tabellenparser}
	\label{sec:modellierung:realisierung:parser}
	
	Der Code zum Parsen der Tabellen-Closures basiert auf dem dem in Abschnitt \ref{sec:modellierung:implementierung:varianten:laufzeit}
	gezeigten Entwurf. Die Logik an sich ist relativ generisch, je nach konkreter Tabelle muss allerdings mit unterschiedliche Datentypen
	gearbeitet werden. 
	
	Folgende zwei Möglichkeiten bieten sich an, den Parser zu realisieren:
	\begin{enumerate}
		\item Für jede Tabellen-Adapter-Klasse wird individueller Parser-Code generiert.
		\item Die Tabellen-Adapter nutzen eine generische Parser-Klasse.
	\end{enumerate}

	Der Nachteil, redundanten Code zu generieren, mag gering erscheinen. Gerade bei generiertem Code wird redundanter Code weniger
	kritisch gesehen. Allerdings erreicht der Code für zum Parsen einer Tabelle eine gewisse Komplexität, die die Pflege des Codes
	auf Template-Ebene erschwert. Die generische Klasse muss zwar einige Hürden überwinden, hat aber einige Vorteile: Die Wartung
	erfolgt IDE-unterstützt und Änderungen erfordern in der Regel keine Neu-Generierung der Tabellen-Klassen. Aus Architektur-Sicht
	ist der größte Vorteil jedoch, dass keine der zu generierenden Klassen spezielle Groovy-Features nutzen muss und es damit 
  ausreicht, Java-Klassen zu verwenden.
	
	Die Schwierigkeiten, die mit der Entscheidung zugunsten des generischen Parsers gelöst werden müssen, betreffen Operationen,
	die der Parser auf der Tabelle durchführen muss: Anlegen neuer Zeilen, Suchen nach Zeilen und Setzen von Werten auf den Zeilen.
	Dies wird unter anderem mit einem weiteren Adapter zwischen den bereits bekannten Table-Adapter-Klassen und dem generischen
	Table-Parser erreicht. Dieser Adapter implementiert das generische Interface \texttt{TableParserAdapter}. Die generischen
	Typ-Parameter enthalten Informationen zu den konkret verwendeten Klassen wie dem RowBuilder. Darüber hinaus bietet es
	die benötigten Methoden zum Erstellen und Suchen von Tabellen-Zeilen.

  Das Setzen der Werte auf den RowBuildern ist deshalb ein Problem, weil die Bezeichner der Set-Methoden die Spaltennamen enthalten.
	Eine Lösung sind die bereits im letzten Abschnitt angesprochenen \texttt{ColumnBinding}-Klasse. Sie definiert die abstrakte
	generische Methode \texttt{set(R row, Object value)}, wobei \texttt{R} der Typ-Parameter für den RowBuilder ist.
	In die Implementierungen der \texttt{set}-Methoden kann der korrekte Bezeichner für den jeweiligen Setter auf dem RowBuilder
	generiert werden.
	
	Außerdem kann der Parser auch Informationen zu der Spalte abfragen, z.B. ob es sich um ein Feld mit einmaligen Werten
	handelt, die zur Identifizierung genutzt werden können. Sofern das Flag aktiviert ist, ist eine Such-Methode auf dem
	\texttt{ColumnBinding} implementiert, die es erlaubt den zu einem Wert gehörenden RowBuilder zu finden.
	
	

	- TableParser (Groovy)
	- TableParserContext
	- TableParserCallback
	- zeilenweise wegen Exceptions
	- Groovy-Anteil minimiert
	- Diagramm :-)
	
	
	\subsection{Referenzen und Scopes}
	\label{sec:modellierung:realisierung:refs_and_scopes}
	
	Neben der Möglichkeit, Daten tabellarisch zu modellieren, gehören die neuen Referenz-Datentypen zu der wichtigsten Erweiterung.
	In \textit{STU} ist eine Referenz eine Art Stellvertreter für eine Entität (Tabellenzeile). Die Referenz kann bei der Modellierung 
	oder auch bei Such-Anfragen anstelle konkreter Werte (wie Primärschlüssel) verwendet werden. Die Such-Anfrage-Möglichkeiten
	werden in Abschnitt \ref{sec:modellierung:realisierung:apierweiterungen} erläutert.
	
	Referenzen müssen an ihre Datensätze gebunden werden. Im Table Builder API ist dafür die Spalte \texttt{REF} vorgesehen,
	die in jeder Tabelle genutzt werden kann, das Fluent Builder API bietet auf den RowBuilder-Klassen die Methode \texttt{bind()}.
	Listings \ref{listing:ref:bindingtable} und \ref{listing:ref:bindingfluent} zeigen die Modellierung der selben Zeile einmal 
	mit dem neuen Table Builder API und einmal mit dem erweiterteren Fluent Builder API.
	
	\begin{lstlisting}[caption=Binden von Referenzen (Table Builder API), label=listing:ref:bindingtable]
professorTable.rows {
  REF    | name    | vorname  | titel            | fakultaet
  WAESCH | "Wäsch" | "Jürgen" | "Prof. Dr.-Ing." | "Informatik"
	...
}
	\end{lstlisting}
  
	\begin{lstlisting}[caption=Binden von Referenzen (Fluent Builder API), label=listing:ref:bindingfluent]
table_Professor.insertRow()
  .bind(WAESCH)
	.setName("Wäsch")
	.setVorname("Jürgen")
	.setTitle("Prof. Dr.-Ing.")
	.setFakultaet("Informatik")
...
	\end{lstlisting}
	
	Da Referenzen die zugehörigen RowBuilder kennen, können ihre Werte auch direkt auf der Referenz abgefragt werden 
	(\reflst{listing:ref:valueaccess}).
	
	\begin{lstlisting}[caption=Zugriff auf Werte über Referenzen, label=listing:ref:valueaccess]
WAESCH.getName()    // Java style
WAESCH.name         // Groovy style
	\end{lstlisting}
	
	Darüber hinaus können über Referenzen Beziehungen modelliert werden. Sie enthalten Methoden zum Ausdrücken von Beziehungen.
	Die Methodennamen entsprechen den im Generator-Modell angegebenen Relationsnamen. Listing \ref{listing:ref:relations} zeigt
	ein Beispiel,wie die Relation zwischen einem Professor und einer Prüfung modellieren lässt.
	\begin{lstlisting}[caption=Definition von Beziehungen über Referenzen, label=listing:ref:relations]
WAESCH.beaufsichtigt(P_VSYS)
	\end{lstlisting}
	
	Die Referenzen müssen vor ihrer Nutzung definiert (also deklariert und instantiiert) werden. Zwar könnten in Groovy auch nicht
	explizit definierte Referenzen verwendet werden, allerdings würde Tool-Unterstützung verloren gehen (z.B. beim Umbenennen von
	Referenzen, Erkennen von Tippfehlern bei Bezeichnern). Außerdem könnten sie auch nicht
	im normalen Java-Code verwendet werden. Es bietet sich an, sie als globale Variablen zu definieren. Verschiedene DataSets (mit
	dem selben Datenbank-Modell) können die selben Referenzen nutzen, auch wenn sie unterschiedliche Werte repräsentieren.
	
	Damit die selben Referenzen in unterschiedlichen DataSets genutzt werden können, werden die RowBuilder immer im Kontext des
	gerade aktiven DataSets gebunden. Das aktive DataSet wird über die \texttt{DataSetRegistry} festgelegt (und abgefragt). Pro
	Datenbank-Modell ist immer ein (oder kein) DataSet aktiv. Das heißt, dass wenn verschiedene Datenbank-Modelle genutzt werden,
	aus jedem Modell jeweils ein DataSet gleichzeitig aktiv sein kann.
	
	\subsection{Beispiel-DataSet in Groovy}
	\label{sec:modellierung:realisierung:beispieldataset}
	
	In Kapitel \ref{chap:anforderungen} wurden Beispiel-Daten in unterschiedlichen Verfahren modelliert. Aufgrund der Übersicht
	wurden dort nur jeweils zwei Tabellen dargestellt. Listing \ref{listing:hochschuledataset:table} zeigt, wie sich die selben
	Daten mit der neuen DSL modellieren lassen - diesmal allerdings in vollem Umfang.
		
	\begin{lstlisting}[caption=DataSet modelliert mit Table Builder API, label=listing:hochschuledataset:table]
class HochschuleDataSet extends HochschuleBuilder
{

  def tables() {

    professorTable.rows {
      REF    | name    | vorname  | titel            | fakultaet
      WAESCH | "Wäsch" | "Jürgen" | "Prof. Dr.-Ing." | "Informatik"
      HAASE  | "Haase" | "Oliver" | "Prof. Dr."      | "Informatik"
    }

    lehrveranstaltungTable.rows {
      REF       | id  | name                | sws | ects
      VSYS      | 1   | "Verteilte Systeme" | 4   | 5
      DPATTERNS | 2   | "Design Patterns"   | 4   | 3
    }

    pruefungTable.rows {
      REF         | id  | typ   | zeitpunkt
      P_VSYS      | 1   | "K90" | DateUtil.getDate(2013, 4, 1, 14, 0, 0)
      P_DPATTERNS | 2   | "M30" | DateUtil.getDate(2013, 1, 6, 12, 0, 0)
    }

    studentTable.rows {
      REF        | matrikelnummer | name         | vorname    | studiengang
      MUSTERMANN | 123456         | "Mustermann" | "Max"      | "BIT"      
      MOLL       | 287336         | "Moll"       | "Nikolaus" | "MSI"      

      REF        | semester | immatrikuliert_seit
      MUSTERMANN | 3        | DateUtil.getDate(2012, 3, 1)
      MOLL       | 4        | DateUtil.getDate(2011, 9, 1)
    }

  }

  def relations() {
    WAESCH.beaufsichtigt(P_VSYS)
    HAASE.leitet(VSYS, DPATTERNS)
    HAASE.beaufsichtigt(P_DPATTERNS)
    P_VSYS.stoffVon(VSYS)
    DPATTERNS.hatPruefung(P_DPATTERNS)
    MOLL.schreibt(P_VSYS)
    MOLL.besucht(VSYS)
    VSYS.hatTutor(MOLL)
    MUSTERMANN.besucht(DPATTERNS)
  }

}
	\end{lstlisting}
	
	Insgesamt ist die Darstellung sehr übersichtlich und kommt ohne syntaktischen Ballast aus. Die DataSet-Klasse
	erweitert die generierte Klasse \texttt{HochschuleBuilder} und überschreibt die beiden Methoden \texttt{tables}
	und \texttt{relations}. In diesen Methoden sollen die Tabellendaten bzw. die Beziehungen der Entitäten
	modelliert werden.
	
	Der Code wurde aufgrund der eingeschränkten Seitenbreite leicht angepasst und die Tabelle mit den Studenten in zwei
	Blöcke aufgeteilt (Zeilen 24 bis 32). In diesem Beispiel ist diese Darstellung eher unüblich, aber der Parser
	unterstützt auch die Definition von Teiltabellen mit unterschiedlichen Spalten innerhalb eines Closures.

	Auffällig ist, dass keine der assoziativen Tabellen explizit auftaucht, diese werden implizit durch die
	Beziehungen modelliert. D.h. assoziativer Beziehungen können mit Hilfe der DSL nicht nur auf Datenbank-Ebene,
	sondern auch auf der abstrakteren ER-Ebene ausgedrückt werden. Es wäre allerdings auch möglich, die
	assoziativen Beziehungen innerhalb der Methode \texttt{tables} zu definieren (siehe Listing 
	\ref{listing:hochschuledataset:tableassoc}).

	\begin{lstlisting}[caption=Assoziative Beziehung über Tabelle, label=listing:hochschuledataset:tableassoc]
class HochschuleDataSet extends HochschuleBuilder
{

  def tables() {
    
		...
		
    beaufsichtigtTable.rows {
      professor | pruefung
      WAESCH    | P_VSYS
      HAASE     | DPATTERNS
    }

  }
	
	...
	
}
	\end{lstlisting}


	\subsection{Nutzung des DataSets in Unit-Tests}
	\label{sec:modellierung:realisierung:junittest}
	
	Wie das Beispiel-DataSet aus Listing \ref{listing:hochschuledataset:table} in einem JUnit-Test verwendet werden kann,
	zeigt Listing \ref{listing:junittest}. Das System Under Test (siehe Abschnitt \ref{sec:grundlagen:konzepte:tests})
	ist ein Spring-Service, der von der Variable \texttt{sut} (Zeile 20) repräsentiert wird. \todo{Quelle Spring Service}
	
	Das in einem Test verwendete DataSet kann als Klasse über die Annotation \texttt{DatabaseSetup} konfiguriert werden
	(Zeile 26). Sie sorgt dafür, dass die angegebene DataSet-Klasse instantiiert und der Variable zugewiesen wird, die 
	mit der Annotation \texttt{InjectDataSet} markiert wurrde (Zeilen 22 und 23). Außerdem wird dieses DataSet auch bei
	der \texttt{DataSetRegistry} als aktives DataSet registriert und die Daten in die Datenbank eingespielt. Dadurch
	kommen die Test-Methoden ohne Verwaltungsaufgaben aus. Der Test \texttt{removeStudent} testet, ob das System die
	richtigen Änderungen macht, wenn der Student \texttt{MUSTERMANN} entfernt wird. Da dem Service die zu löschende
	Entität übergeben werden muss (Zeile 38), wird in den Zeilen 29 bis 35 eine entsprechende Instanz erstellt und
	konfiguriert. 
	
	\begin{lstlisting}[caption=JUnit-Tests (reiner Java-Code), label=listing:junittest]
@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration(classes=HochschuleContext.class)
public class HochschuleDataSetDatabaseTest {

  @Autowired
  DataSource dataSource;

  @Rule
  public DatabaseTesterRule dbTester =
     new DatabaseTesterRule(new Future<DataSource>(){
       @Override
       public DataSource getFuture()
       {
         return dataSource;
       }
     }).addCleanAction(new ApacheDerbySequenceReset()
		   .autoDerivateFromTablename("_SEQ"));

  @Autowired
  HochschuleService sut;

  @InjectDataSet
  HochschuleBuilder dataSet;

  @Test
  @DatabaseSetup(prepare = HochschuleDataSet.class)
  public void removeStudent() throws Exception {
    // prepare
    Student student = new Student();
    student.setMatrikelnummer(MUSTERMANN.getMatrikelnummer());
    student.setVorname(MUSTERMANN.getVorname());
    student.setName(MUSTERMANN.getName());
    student.setStudiengang(MUSTERMANN.getStudiengang());
    student.setSemester(MUSTERMANN.getSemester());
    student.setImmatrikuliertSeit(MUSTERMANN.getImmatrikuliertSeit());

    // execute
    sut.removeStudent(student);

    // verify
    dataSet.studentTable.deleteRow(MUSTERMANN);
    dataSet.besuchtTable.deleteAllAssociations(MUSTERMANN);

    dbTester.assertDataBase(dataSet);
  }
	
	...

}	
	\end{lstlisting}
	
	In den Zeilen 41 und 42 werden die erwarteten Änderungen im DataSet ebenfalls durchgeführt, um in Zeile 44 die
	Datenbank gegen das DataSet zu vergleichen.
	
	Die neue DSL kann in Groovy-basierten Tests verwendet werden. Listing \ref{listing:junittest:groovy} zeigt
	beispielhaft eine entsprechende Test-Methode. In diesem Test wird eine neue Lehrveranstaltung erstellt und
	einem Professor zugeordnet.
	
	\begin{lstlisting}[caption=Test-Methode in Groovy, label=listing:junittest:groovy]
  @Test
  @DatabaseSetup(prepare = HochschuleDataSet)
  def addLehrveranstaltung() {
    // prepare
    Lehrveranstaltung lv = new Lehrveranstaltung()
    lv.setName("Programmieren")
    lv.setProfessor(HAASE.id)
    lv.setSws(4)
    lv.setEcts(6.0)

    // execute
    def addedLv = sut.addLehrveranstaltung(lv)

    // verify
    dataSet.lehrveranstaltungTable.rows {
      id         | professor | name            | sws | ects
      addedLv.id | HAASE     | "Programmieren" | 4   | 6.0
    }

    dbTester.assertDataBase(dataSet)
  }
	\end{lstlisting}
	
	Sicherheitshalber wird die vom Spring-Service erzeugte ID verwendet, um die Änderungen am DataSet
	nach zu modellieren. Auf diese Weise bleibt der Test stabil, auch wenn sich das Verhalten des Services
	bezüglich der ID-Generierung ändern sollte.
		
	\subsection{Komposition von DataSets}
	\label{sec:modellierung:realisierung:kompositiondatasets}
	
	DataSets lassen sich für Tests auch aus anderen zusammensetzen. Dieses Feature setzt nicht auf Konzepte
	der Objektorientierung wie Vererbung. Vererbung würde zu mehr syntaktischem Ballast führen, da die Methoden
	\texttt{tables} und \texttt{relations} explizit die Methoden aus der Super-Klasse aufrufen müssten. 
	
	Der realisierte Mechanismus sieht vor, dass die DataSet-Klassen, die als Basis für das gerade definierte
	DataSet dienen sollen, über die Hook-Methoden \texttt{extendsDataSet} (bei einem Basis-DataSet) bzw.
	\texttt{extendsDataSets} (für mehrere Basis-DataSets) zurückgeliefert werden. Listing
	\ref{listing:extendeddataset} zeigt, wie ein DataSet ein anderes als Basis verwendet. 
	
	\begin{lstlisting}[caption=Erweitertes DataSet, label=listing:extendeddataset]
class ExtendedHochschuleDataSet extends HochschuleBuilder {

  def extendsDataSet() { HochschuleDataSet }

  def tables() {

   lehrveranstaltungTable.rows {
      REF       | id  | name                | sws | ects
      PROGR     | 3   | "Programmieren"     | 4   | 6.0
		}
  
	}

  def relations() {
    HAASE.leitet(PROGR)
  }

}	
	\end{lstlisting}
	
	Die Syntax für die Komposition aus den drei DataSet-Klassen \texttt{DataSet1}, \texttt{DataSet2} und
	\texttt{DataSet3} ist in Listing \ref{listing:multiextendeddataset} dargestellt:
	\begin{lstlisting}[caption=Erweitertes DataSet, label=listing:multiextendeddataset]
  def extendsDataSets() { [ DataSet1, DataSet2, DataSet3 ] }
	\end{lstlisting}
	
	Das erweiterte DataSet kann in den selben Unit-Tests verwendet werden. Dabei reicht es aus,
	die Annotation \texttt{DatabaseSetup} entsprechend anzupassen (siehe Listing 
	\ref{listing:junittest:extendeddataset}).
	
	\begin{lstlisting}[caption=Test auf erweiterem DataSet, label=listing:junittest:extendeddataset]
  @Test
  @DatabaseSetup(prepare = ExtendedHochschuleDataSet)
  public void assignedLehrveranstaltungen() throws Exception {
    // prepare
    Professor haase = new Professor();
    haase.setId(HAASE.id);

    // execute
    List<Lehrveranstaltung> items = sut.findLehrveranstaltungen(haase);

    // verify
		def findWhere = dataSet.lehrveranstaltungTable.findWhere
    int count = findWhere.professorId(HAASE).rowCount
    assertThat(items).hasSize(count);
  }
	\end{lstlisting}

  \subsection{Erweiterungen in generierter API}
	\label{sec:modellierung:realisierung:apierweiterungen}
	
	Die meisten Erweiterungen an der Fluant-Builder-API-Schicht betreffen die Möglichkeit, Ref-Typen statt konkreter Werte
	zu verwenden. Dazu gehören unter anderem:
	
	\begin{itemize}
		\item \textbf{RowBuilder}: Die Erweiterungen der RowBuilder betreffen vor allem die verbesserten Möglichkeiten
		  Relationen auszudrücken. So gibt es für Spalten, die eine Relation zu einer anderen Spalte enthalten, nun neben
			einem Setter für den konkreten Wert (z.B. des Fremdschlüssels) einen Setter zum Setzen des entsprechenden
			Ref-Typs. 
			
		  Anstelle des von der Ref repräsentierten Wertes wird die Ref selbst im RowBuilder abgespeichert. Das hat zwei
			Vorteile:
     	\begin{enumerate}
		    \item \textbf{Reihenfolge}: Die Modellierung der Daten ist in diesem Fall keiner strengen Reihenfolge unterworfen.
				  Es ist egal, ob die Zeile, auf die Bezug genommen wird, überhaupt schon initialisiert wurde.

		    \item \textbf{Konsistenz}: Die Werte werden nicht redundant gespeichert. Wird der Wert an einer Stelle geändert,
				  ist dieser Wert unmittelbar im gesamten DataSet so sichtbar.
		  \end{enumerate}
			
		\item \textbf{Future Values}: Eine der wenigen Erweiterungen, die nicht auf die Einführung der Ref-Typen zurückzuführen
		  sind, sind Future Values. Dabei handelt es sich um Werte, die erst beim Abfragen ausgewertet werden. Dies kann nützlich
			sein, wenn sich Werte abhängig von anderen Daten ändern. Listing \ref{listing:futurevalues} zeigt ein Beispiel, in der
			die Lehrveranstaltungstabelle um eine Spalte erweitert wurde. Diese Spalte soll die Anzahl der Tutoren aufnehmen, die
			die Lehrveranstaltung betreuen.
		
	    \begin{lstlisting}[caption=Beispiel Lazy Valunes, label=listing:futurevalues]
class HochschuleDataSet extends HochschuleBuilder
{

  def tables() {
        
    lehrveranstaltungTable.rows {
      REF       | name                | sws | ects | tutoren
      VSYS      | "Verteilte Systeme" | 4   | 5    | tutors(VSYS)
      DPATTERNS | "Design Patterns"   | 4   | 3    | tutors(DPATTERNS)
    }
    
    ...
  }
    
  ...

  // returns a Closure which is threated as future value
  def tutors(LehrveranstaltungRef ref) {
    return {
      // findWhere throws an exception if no rows are found
      if (isttutorTable.getWhere.lehrveranstaltungId(ref).present) { 
        def rows = isttutorTable.findWhere.lehrveranstaltungId(ref);
        return rows.getRowCount()
      }
      return 0;
    }
  }
}
  	  \end{lstlisting}
			
			Durch die Nutzung von Future Values enthält die Tabelle immer die korrekte Anzahl, ohne dass beim Modellieren
	    der Tutoren-Beziehungen Anpassungen notwendig wurden. In Groovy können Closures verwendet werden, ...


    \item \textbf{findWhere}: Das bisherige API sah Suchen von Zeilen in einer Tabelle ausschließlich über konkrete Werte
		  vor. Die Erweiterung ermöglicht es, dass Ref-Typen statt konkreter Werte verwendet werden können. Werden beispielsweise 
			in der Professor-Tabelle alle Professoren mit einem bestimmten Vornamen gesucht und als Such-Wert eine 
			Professor-Referenz übergeben, werden alle Professoren mit diesem Vornamen gesucht. Listing
			\ref{listing:apierweiterung:findexample} zeigt zwei Such-Anfragen, die beide auf den Beispieldaten das selbe Ergebnis
			liefern.
	
	    \begin{lstlisting}[caption=Such-Beispiele, label=listing:apierweiterung:findexample]
dataSet.table_Professor.findWhere.vorname("Oliver");
dataSet.table_Professor.findWhere.vorname(HAASE);
	    \end{lstlisting}

		  
	  \item \textbf{getWhere}:
		  - Zusätzlich zu findWhere
	  
		\item \textbf{find}: Sind die einfachen Such-Anfragen über \texttt{findWhere} bzw. \texttt{getWhere} nicht mächtig genug,
		  können mit Hilfe von \texttt{find} Filter-basierte Suchen durchgeführt werden. In Listing \ref{listing:find} wird
			ein Filter gezeigt, der alle Professoren findet, deren Vorname die Länge sechs hat.
			
	    \begin{lstlisting}[caption=Beispiel für find, label=listing:find]
Filter<RowBuilder_Professor> FILTER = 
  new Filter<RowBuilder_Professor>() 
	  {
		  @Override
		  public boolean accept(RowBuilder_Professor value)
		  {
			  return value.getVorname().length() == 6;
		  }
	  };
		
RowCollection_Professor profs = dataSet.professorTable.find(FILTER);
  	  \end{lstlisting}
			
			In Groovy können auch direkt Closures übergeben werden, die als Argument einen entsprechenden RowBuilder übergeben
			bekommen.
	  
    \item \textbf{foreach}:
	    \begin{lstlisting}[caption=Beispiel für foreach, label=listing:foreach]
Action<RowBuilder_Professor> ACTION = 
  new Action<RowBuilder_Professor>() 
	  {
		  @Override
		  public void call(RowBuilder_Professor value)
		  {
			  System.out.println("Professor: " + value.getName());
		  }
	  };
	
dataSet.professorTable.foreach(ACTION);
  	  \end{lstlisting}
				
	\end{itemize}
	
	\subsection{JavaDoc}
	\label{sec:modellierung:realisierung:javadoc}
	
	Zum guten IDE-Support gehört auch, dass der Tester beim Erstellen der Tests durch aussagekräftige
	JavaDoc unterstützt wird.

\begin{figure}[H]
	\centering
	 \includegraphics[scale=0.4]{images/realisierung/javadoc_tooltip_builder.png}
	\caption{Tooltip Builder}\label{img:javadoc_tooltip_builder}
\end{figure}

\begin{figure}[H]
	\centering
	 \includegraphics[scale=0.4]{images/realisierung/javadoc_tooltip_tables.png}
	\caption{Tooltip tables()}\label{img:javadoc_tooltip_tables}
\end{figure}

\begin{figure}[H]
	\centering
	 \includegraphics[scale=0.4]{images/realisierung/javadoc_tooltip_relations.png}
	\caption{Tooltip relations()}\label{img:javadoc_tooltip_relations}
\end{figure}

\begin{figure}[H]
	\centering
	 \includegraphics[scale=0.4]{images/realisierung/javadoc_tooltip_table.png}
	\caption{Tooltip Tabelle}\label{img:javadoc_tooltip_table}
\end{figure}

\begin{figure}[H]
	\centering
	 \includegraphics[scale=0.4]{images/realisierung/javadoc_tooltip_rows.png}
	\caption{Tooltip Zeilen}\label{img:javadoc_tooltip_rows}
\end{figure}

  \subsection{Verhalten bei Fehlern in den Tabellendefinitionen}
	


  \subsection{Nicht umgesetzt}
	\label{sec:modellierung:realisierung:nichtumgesetzt}
	
	Die Realisierung könnte an manchen Stellen dem Test-Ingenieur mehr manuelle Arbeit abnehmen. So wird darauf verzichtet,
	beim Löschen einer Zeile aus einer Tabelle auch alle beteiligten Beziehungen zu entfernen. Listing \ref{listing:deleteexample}
	zeigt, wie ein Professor aus der Professoren-Tabelle entfernt wird. Die erste Zeile entfernt keine Einträge in 
	anderen Tabellen wie z.B. der Beaufsichtigt-Tabelle. Folglich müssen die Relationen (mehr oder weniger) manuell
	aus anderen Tabellen entfernt werden.

  \begin{lstlisting}[caption=Löschen von Zeilen, label=listing:deleteexample]
dataSet.professorTable.deleteRow(HAASE);
dataSet.beaufsichtigtTable.deleteAllAssociations(HAASE);
  \end{lstlisting}
	
	Diese Entscheidung hat unterschiedliche Gründe:
	\begin{itemize}
		\item \textbf{Einsatzgebiet}: Die Bibliothek soll Unit-Tests in Verbindung mit Datenbanken vereinfachen. Es handelt sich
		  hier nicht um ein API, das in einer Anwendung ausgeliefert wird. Während es in einem API für produktive Anwendungen
			durchaus wünschenswert sein kann, dass das System beim Löschen von Entitäten gewisse Aufgaben automatisch erledigt,
			ist so ein Verhalten innerhalb einer Test-Bibliothek zweifelhaft. Explizites Löschen von Zeilen auf allen beteiligten
			Tabellen verbessert die Ausdrucksstärke des Tests.
			
		\item \textbf{Code-Qualität}: Eine Funktion (bzw. Methode) sollte genau eine Aufgabe erledigen. Wenn
		  \texttt{deleteRow} zusätzlich beteiligte Relationen auflöst, erledigt diese Funktion mehr als nur eine Aufgabe 
			\cite[65f]{CLEAN_CODE}. Außerdem würde es sich um einen unerwarteten Nebeneffekt handeln \cite[75f]{CLEAN_CODE}.
		
		\item \textbf{Klarheit}: Es ist nicht eindeutig, wie beim Entfernen von Zeilen vorgegangen werden soll, wenn sie
		  Teil einer Relation sind. Bei einer n:m-Relation könnte sich die Regel ableiten lassen, dass beim Löschen einer
			Zeile auch alle assoziierten n:m-Relationen entfernt werden können. Aber was ist bei einer 1:n-Relation? Wenn
			ein Professor entfernt wird, was soll mit Lehrveranstaltungen passieren, die ihm zugeordnet sind?
	\end{itemize}

  
		
\todo{"`Muster"' für 1:1, 1:n und m:n}
